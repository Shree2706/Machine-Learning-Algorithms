## 2. Gradient Descent Algorithm
Gradient Descent is a first order iterative optimization algorithm for finding a local minima of a differentiable function. 
In simple words, GD will give minima of any differentiable function whenever multi dimensional data is given to it.
Types of Gradient Descent:
  1. Batch Gradient Descent - It is the default Gradient Descent that we use, but that is in 2D, and it can also be used in n no. dimensions (3D, 4D ... nD).
  2. Stochastic Gradient Descent - In Stochastic Gradient Descent, we only see the first data or any one random data for one epoch and they try to predict how much change s required for the next prediction.
  3. Mini Batch Gradient Descent - Mini-batch gradient descent is a gradient descent modification that divides the training dataset into small batches that are used to compute model error and update model coefficients.


